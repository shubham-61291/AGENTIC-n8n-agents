HR Chatbot with Website Integration (n8n + Google Gemini + Supabase + Postgres)

Purpose
This agent powers a website-integrated HR chatbot that answers user questions using your private HR knowledge base. It receives chat messages via a public webhook, retrieves relevant context from a Supabase vector store, keeps conversation memory in Postgres, and generates answers with Google Gemini. It also includes a document-ingestion path to chunk and embed new files into the vector store. 

Core flow (runtime)

Trigger: “When chat message received” (public webhook).

LLM: Google Gemini Chat Model generates responses.

Memory: Postgres Chat Memory stores conversation history for better continuity.

Retrieval: Supabase Vector Store in “retrieve-as-tool” mode provides RAG context to the AI Agent (tool description currently set to “HR POLICY FOR SUPERNOVA”).

Agent: AI Agent orchestrates LLM + memory + retrieval and returns final answers to the chat trigger. 

Ingestion flow (to load knowledge)

Document Default Data Loader (expects binary file input).

Character Text Splitter with custom settings (separator “1000”, chunk overlap 150).

Embeddings Google Gemini to embed chunks.

Supabase Vector Store (mode “insert”) to write embeddings and texts into your Supabase table (default shown as “documents”). 

What each node does

When chat message received: exposes a public webhook to receive chat messages from your site or widget.

AI Agent: runs with a system message that tells it to retrieve and present relevant information from the vector store.

Google Gemini Chat Model: primary LLM for answer generation.

Postgres Chat Memory: persists chat history so answers can be contextual and multi-turn.

Supabase Vector Store (retrieve-as-tool): RAG retrieval tool used by the agent at answer time (table “documents”, tool description “HR POLICY FOR SUPERNOVA”).

Embeddings Google Gemini: embedding model used for retrieval and for ingestion.

Default Data Loader: reads binary files (PDFs, docs) for ingestion.

Character Text Splitter: splits loaded text into chunks with overlap.

Supabase Vector Store (insert): writes embedded chunks into the vector store. 

Setup (step by step)

Import the workflow

In n8n, go to Workflows → Import from File and load the JSON.

Connect credentials (in n8n Credentials)

Gemini (PaLM/Gemini) API: add your key and bind it to the Google Gemini Chat Model and Embeddings nodes.

Postgres: add a connection for the memory node (host, port, database, user, password, SSL as needed).

Supabase: add your Supabase URL and API key; bind to both Supabase Vector Store nodes (retrieve + insert). 

Configure data store details

Supabase table: replace the table name “documents” with your own if different.

Tool description: change “HR POLICY FOR SUPERNOVA” to describe your actual knowledge domain (e.g., “HR Policy Handbook”). 

Expose the chatbot on your website

Open the “When chat message received” node and copy the webhook URL.

Connect your website chat widget or POST chat messages (JSON) to this webhook.

Keep the node public or secure it behind your preferred method (reverse proxy, token, IP allowlist).

Ingest content (populate the vector store)

In n8n, execute the ingestion path: provide a binary file to the Default Data Loader (e.g., upload a PDF via UI or add a separate upload webhook).

Ensure the Character Text Splitter and Embeddings nodes run, then confirm inserts land in your Supabase “documents” table. 

Environment and placeholders to set (no secrets in JSON)

YOUR_WEBHOOK_URL (generated by the chat trigger after import).

YOUR_GEMINI_API_KEY (for the chat model and embeddings).

YOUR_SUPABASE_URL and YOUR_SUPABASE_API_KEY (vector store).

YOUR_POSTGRES_CONNECTION (host, port, db, user, password, SSL) for chat memory.

YOUR_TABLE_NAME (default “documents”; change if you use a different schema).

YOUR_TOOL_DESCRIPTION (domain phrase the agent uses when retrieving context).

Security notes

The chat webhook is public by default; protect it if needed (token header, IP allowlist, or put n8n behind an authenticated gateway).

Never commit live API keys or database credentials. Store all secrets in n8n Credentials or environment variables.

Validate uploaded files before ingestion if you add a public upload route.

Testing

Send a test message to the webhook; verify the AI response includes retrieved snippets from your knowledge base.

Ingest a small PDF (e.g., two pages), then ask a question that should be answerable only from that PDF to confirm retrieval is working.

Check Postgres to ensure new conversations are saved and recalled in later turns. 

Troubleshooting

If answers ignore your documents, confirm embeddings exist in Supabase and the retrieve-as-tool node points to the correct table.

If memory does not stick, verify Postgres credentials and that the memory node is connected to the agent.

If the webhook returns 404/401, re-copy the exact production URL from the node after saving the workflow.

DEMO VIDEO :- https://www.youtube.com/watch?v=czIQ1PzZAg0&list=PLlRRgrbOaGcaHAbVCTk70Nf0GerWXrqy1&index=5

Author
Shubham Singh

License
MIT License
